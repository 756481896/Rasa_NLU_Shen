{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m rasa_nlu.train -c sample_configs/config_shen_test3.yml data/rasa_nlpcc.json -o models --fixed_model_name nlpcc --project current --verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-16 21:05:30 INFO     rasa_nlu.training_data.loading  - Training data format of /home1/shenxing/Rasa_NLU_Chi/data/rasa_nlpcc.json is rasa_nlu\n",
      "2018-10-16 21:05:31 INFO     rasa_nlu.training_data.training_data  - Training data stats: \n",
      "\t- intent examples: 21352 (11 distinct intents)\n",
      "\t- Found intents: 'navigation.cancel_navigation', 'OTHERS', 'music.pause', 'music.next', 'phone_call.make_a_phone_call', 'music.play', 'navigation.open', 'navigation.navigation', 'navigation.start_navigation', 'phone_call.cancel', 'music.prev'\n",
      "\t- entity examples: 10888 (15 distinct entities)\n",
      "\t- found entities: 'song', 'theme', 'phone_num', 'style', 'language', 'instrument', 'age', 'scene', 'singer', 'contact_name', 'origin', 'custom_destination', 'emotion', 'toplist', 'destination'\n",
      "\n",
      "2018-10-16 21:05:31 INFO     rasa_nlu.utils.spacy_utils  - Trying to load spacy model with name 'zh'\n",
      "2018-10-16 21:05:34 INFO     rasa_nlu.components  - Added 'nlp_spacy' to component cache. Key 'nlp_spacy-zh'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load sentiment analyzer.Text:  这件衣服的质量也太差了吧！ score 0.09661951767426591\n",
      "No Jieba Default Dictionary found\n",
      "No Jieba User Dictionary found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-16 21:05:36 INFO     rasa_nlu.model  - Starting to train component nlp_spacy\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 1.237 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "2018-10-16 21:10:49 INFO     rasa_nlu.model  - Finished training component.\n",
      "2018-10-16 21:10:49 INFO     rasa_nlu.model  - Starting to train component sentiment_analyzer\n",
      "2018-10-16 21:10:49 INFO     rasa_nlu.model  - Finished training component.\n",
      "2018-10-16 21:10:49 INFO     rasa_nlu.model  - Starting to train component tokenizer_jieba\n",
      "2018-10-16 21:10:50 INFO     rasa_nlu.model  - Finished training component.\n",
      "2018-10-16 21:10:50 INFO     rasa_nlu.model  - Starting to train component ner_spacy\n",
      "2018-10-16 21:10:50 INFO     rasa_nlu.model  - Finished training component.\n",
      "2018-10-16 21:10:50 INFO     rasa_nlu.model  - Starting to train component intent_entity_featurizer_regex\n",
      "2018-10-16 21:10:50 INFO     rasa_nlu.model  - Finished training component.\n",
      "2018-10-16 21:10:50 INFO     rasa_nlu.model  - Starting to train component intent_featurizer_spacy\n",
      "2018-10-16 21:10:50 INFO     rasa_nlu.model  - Finished training component.\n",
      "2018-10-16 21:10:50 INFO     rasa_nlu.model  - Starting to train component intent_classifier_sklearn\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 6 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed: 240.5min finished\n",
      "2018-10-17 01:17:12 INFO     rasa_nlu.model  - Finished training component.\n",
      "2018-10-17 01:17:12 INFO     rasa_nlu.model  - Successfully saved model into '/home1/shenxing/Rasa_NLU_Chi/projects/default/model_20181017-011712'\n"
     ]
    }
   ],
   "source": [
    "from rasa_nlu.training_data import load_data\n",
    "from rasa_nlu.config import RasaNLUModelConfig\n",
    "from rasa_nlu.model import Trainer\n",
    "\n",
    "training_data = load_data('data/examples/rasa/demo-rasa_zh.json')\n",
    "# training_data = load_data(\"/home1/shenxing/Rasa_NLU_Chi/data/rasa_nlpcc.json\")\n",
    "pipeline = [{\"name\": \"nlp_spacy\"}, \n",
    "            {\"name\": \"sentiment_analyzer\"}, \n",
    "            {\"name\": \"tokenizer_jieba\"}, \n",
    "            {\"name\": \"ner_spacy\"},\n",
    "            {\"name\": \"intent_entity_featurizer_regex\"},\n",
    "            {\"name\": \"intent_featurizer_spacy\"},\n",
    "            {\"name\": \"intent_classifier_sklearn\"}]\n",
    "#             {\"name\": \"spell_checker\"}, \n",
    "trainer = Trainer(RasaNLUModelConfig({\"pipeline\": pipeline,\"language\":\"zh\"}))\n",
    "interpreter = trainer.train(training_data)\n",
    "model_directory = trainer.persist('./projects/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m rasa_nlu.train --config   --data nlu.md -o models --fixed_model_name nlu --project current --verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasa_nlu.training_data import load_data\n",
    "from rasa_nlu import config\n",
    "from rasa_nlu.model import Trainer, Metadata, Interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasa_nlu.evaluate import *\n",
    "test_data = training_data.load_data('/home1/shenxing/Rasa_NLU_Chi/data/rasa_nlpcc_little.json')\n",
    "extractors = get_entity_extractors(interpreter)\n",
    "\n",
    "entity_predictions, tokens = get_entity_predictions(interpreter,\n",
    "                                                        test_data)\n",
    "\n",
    "intent_targets = get_intent_targets(test_data)\n",
    "\n",
    "intent_predictions = get_intent_predictions(interpreter, test_data)\n",
    "logger.info(\"Intent evaluation results:\")\n",
    "evaluate_intents(intent_targets, intent_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap\n",
    "print('stuff')\n",
    "with open('output.txt', 'w') as f:\n",
    "    f.write(cap.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            {\"name\": \"ner_crf\",\"features\":[\n",
    "              [\"low\", \"title\", \"upper\"],\n",
    "              [\"bias\", \"upper\", \"title\", \"digit\", \"pattern\"],\n",
    "              [\"low\", \"title\", \"upper\"]\n",
    "            ]},"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_directory = trainer.persist('./projects/default/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intent': {'name': 'music.play', 'confidence': 0.7548314797698835},\n",
       " 'entities': [{'entity': 'PERSON',\n",
       "   'value': '周杰论',\n",
       "   'start': 3,\n",
       "   'confidence': None,\n",
       "   'end': 6,\n",
       "   'extractor': 'ner_spacy'}],\n",
       " 'sentiment_score': 0.142442561591541,\n",
       " 'intent_ranking': [{'name': 'music.play', 'confidence': 0.7548314797698835},\n",
       "  {'name': 'OTHERS', 'confidence': 0.2076773956888914},\n",
       "  {'name': 'phone_call.make_a_phone_call', 'confidence': 0.018965588244705102},\n",
       "  {'name': 'navigation.navigation', 'confidence': 0.009809803192372039},\n",
       "  {'name': 'music.next', 'confidence': 0.004264023227106449},\n",
       "  {'name': 'navigation.cancel_navigation', 'confidence': 0.001678040786328472},\n",
       "  {'name': 'music.pause', 'confidence': 0.0016641498436464983},\n",
       "  {'name': 'music.prev', 'confidence': 0.0008157769162090125},\n",
       "  {'name': 'navigation.open', 'confidence': 0.00012505498367229565},\n",
       "  {'name': 'phone_call.cancel', 'confidence': 0.00010113210626478231}],\n",
       " 'text': '我要打周杰论的歌'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"我要打周杰论的歌\"\n",
    "interpreter.parse(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intent': {'name': 'music.play', 'confidence': 0.6114427943843772},\n",
       " 'entities': [],\n",
       " 'sentiment_score': 0.8447718984323791,\n",
       " 'intent_ranking': [{'name': 'music.play', 'confidence': 0.6114427943843772},\n",
       "  {'name': 'OTHERS', 'confidence': 0.37189786520102985},\n",
       "  {'name': 'phone_call.make_a_phone_call', 'confidence': 0.008304119577504281},\n",
       "  {'name': 'music.next', 'confidence': 0.004087118776968789},\n",
       "  {'name': 'navigation.navigation', 'confidence': 0.0029661917514812544},\n",
       "  {'name': 'music.pause', 'confidence': 0.0008057115002367483},\n",
       "  {'name': 'navigation.cancel_navigation',\n",
       "   'confidence': 0.00022628329779685193},\n",
       "  {'name': 'music.prev', 'confidence': 0.00016002032435842787},\n",
       "  {'name': 'phone_call.cancel', 'confidence': 4.1910408981073587e-05},\n",
       "  {'name': 'navigation.start_navigation',\n",
       "   'confidence': 4.070706412359977e-05}],\n",
       " 'text': '播放一手周杰论的哥'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"播放一手周杰论的哥\"\n",
    "interpreter.parse(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xmnlp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:  这件衣服的质量也太差了吧！\n",
      "Score:  0.09661951767426591\n",
      "Text:  这酒店真心不错\n",
      "Score:  0.7947237609561072\n"
     ]
    }
   ],
   "source": [
    "doc = \"\"\"这件衣服的质量也太差了吧！\"\"\"\n",
    "doc2 = \"\"\"这酒店真心不错\"\"\"\n",
    "print('Text: ', doc)\n",
    "print('Score: ', xmnlp.sentiment(doc))\n",
    "print('Text: ', doc2)\n",
    "print('Score: ', xmnlp.sentiment(doc2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load sentiment analyzer.Text:  这件衣服的质量也太差了吧！ score 0.09661951767426591\n"
     ]
    }
   ],
   "source": [
    "print('Load sentiment analyzer.Text: ', doc,'score',xmnlp.sentiment(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-11 19:17:10,073 - /home1/shenxing/anaconda3/lib/python3.6/site-packages/pycorrector/corrector.py - DEBUG - Loaded same pinyin file: /home1/shenxing/anaconda3/lib/python3.6/site-packages/pycorrector/data/same_pinyin.txt, same stroke file: /home1/shenxing/anaconda3/lib/python3.6/site-packages/pycorrector/data/same_stroke.txt, spend: 0.026 s.\n",
      "2018-10-11 19:17:10,075 - /home1/shenxing/anaconda3/lib/python3.6/site-packages/pycorrector/detector.py - DEBUG - Loaded language model: /home1/shenxing/anaconda3/lib/python3.6/site-packages/pycorrector/data/kenlm/people_chars_lm.klm, spend: 0.0006983280181884766 s\n",
      "2018-10-11 19:17:10,666 - /home1/shenxing/anaconda3/lib/python3.6/site-packages/pycorrector/detector.py - DEBUG - Loaded word freq file: /home1/shenxing/anaconda3/lib/python3.6/site-packages/pycorrector/data/word_dict.txt, spend: 0.5896639823913574 s\n",
      "2018-10-11 19:17:10,668 - /home1/shenxing/anaconda3/lib/python3.6/site-packages/pycorrector/detector.py - DEBUG - Loaded confusion file: /home1/shenxing/anaconda3/lib/python3.6/site-packages/pycorrector/data/custom_confusion.txt, spend: 0.5914807319641113 s\n",
      "/home1/shenxing/anaconda3/lib/python3.6/site-packages/numpy/lib/function_base.py:1128: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/home1/shenxing/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "2018-10-11 19:17:10,671 - /home1/shenxing/anaconda3/lib/python3.6/site-packages/pycorrector/detector.py - WARNING - detect error, sentence:'numpy.float64' object is not iterable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []\n"
     ]
    }
   ],
   "source": [
    "import pycorrector\n",
    "\n",
    "corrected_sent, detail = pycorrector.correct('')\n",
    "print(corrected_sent, detail)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
